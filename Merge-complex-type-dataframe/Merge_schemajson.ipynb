{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create SparkSession and import all required packages\n",
    "from pyspark.sql import SparkSession,types\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName('Json File')\\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read multiline JSON file\n",
    "input_df=spark.read.json('input2.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Education: struct (nullable = true)\n",
      " |    |-- Qualification: string (nullable = true)\n",
      " |    |-- year: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read multiline JSON file\n",
    "input_df1=spark.read.json('input1.json', multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Education: struct (nullable = true)\n",
      " |    |-- Age: long (nullable = true)\n",
      " |    |-- Qualification: string (nullable = true)\n",
      " |    |-- year: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructField(Education,StructType(List(StructField(Qualification,StringType,true),StructField(year,LongType,true))),true)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_df.schema['Education']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col,lit,struct\n",
    "\n",
    "def flatten_struct(schema, prefix=\"\"):\n",
    "    result = []\n",
    "    for elem in schema:\n",
    "        if isinstance(elem.dataType, StructType):\n",
    "            result += flatten_struct(elem.dataType, prefix + elem.name + \".\")\n",
    "           # result.replace(\"Column<b\",\"\")\n",
    "        else:\n",
    "            result.append(col(prefix + elem.name).alias(prefix + elem.name))\n",
    "    return result\n",
    "\n",
    "l1=flatten_struct(input_df.schema)\n",
    "l2=flatten_struct(input_df1.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Column<b'Education.Age AS `Education.Age`'>,\n",
       " Column<b'Education.Qualification AS `Education.Qualification`'>,\n",
       " Column<b'Education.year AS `Education.year`'>,\n",
       " Column<b'name AS `name`'>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list1=[]\n",
    "list2=[]\n",
    "for i in l1:\n",
    "    list1.append(str(i).split(\"`\")[1])\n",
    "    \n",
    "for i in l2:\n",
    "    list2.append(str(i).split(\"`\")[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Education.Age'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk=set(list2)-set(list1)\n",
    "chk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "chk=set(list2)-set(list1)\n",
    "for i in chk:\n",
    "    if i.find(\".\"):\n",
    "        colm=i.split(\".\")[0]\n",
    "        colm_new=i.split(\".\")[1]\n",
    "        s_fields = input_df.schema[colm].dataType.names\n",
    "        s_type=input_df1.schema[colm].dataType[colm_new].dataType\n",
    "                \n",
    "        in_df=input_df.withColumn(colm,\n",
    "                            struct(*([col(colm)[c].alias(c) for c in s_fields] +\n",
    "                                     [lit(\"null\").cast(s_type).alias(colm_new)]\n",
    "                                     ))\n",
    "                                 )\n",
    "        s_fields = sorted(in_df.schema[colm].dataType.names)\n",
    "        \n",
    "        in_df=in_df.withColumn(colm,\n",
    "                            struct(*([col(colm)[c].alias(c) for c in s_fields] ))\n",
    "                                 )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Education: struct (nullable = false)\n",
      " |    |-- Age: long (nullable = true)\n",
      " |    |-- Qualification: string (nullable = true)\n",
      " |    |-- year: long (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "in_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df=in_df.union(input_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+\n",
      "|       Education|   name|\n",
      "+----------------+-------+\n",
      "|    [, BE, 2011]| Clarke|\n",
      "|    [, BE, 2010]|Michael|\n",
      "|[28, BCOM, 2013]|   AZAR|\n",
      "|  [35, BE, 2010]|   CHIN|\n",
      "+----------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
